# Implement and Review paper related to Vision Transformer

### Implementation or Review Paper List
- [x] [ViT (ICLR 2021)](https://github.com/Sangh0/Vision-Transformer/tree/main/ViT) (classification or backbone network)
- [ ] [DeiT (2021)](https://github.com/Sangh0/Vision-Transformer/tree/main/DeiT) (classification or backbone network)
- [x] [Swin Transformer (2021)](https://github.com/Sangh0/Vision-Transformer/tree/main/SwinTransformer) (classification or backbone network)
- [ ] [Segmenter (ICCV 2021)](https://github.com/Sangh0/Vision-Transformer/tree/main/Segmenter) (semantic segmentation)
- [x] [SETR (CVPR 2021)](https://github.com/Sangh0/Vision-Transformer/tree/main/SETR) (semantic segmentation)

<img src = "https://github.com/Sangh0/Vision-Transformer/blob/main/ViT/figure/Transformer.JPG?raw=true" width=500>

## What is Vision Transformer?  

- Vision Transformer is a model for image classification inspired by Transformer in NLP  
- This deal with image patches like words in NLP
- Self-Attention is important main idea 
- It dosen't use CNN completely and achieved SOTA in each task of Vision 